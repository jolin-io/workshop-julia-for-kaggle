{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jolin-io/workshop-julia-for-kaggle/main?filepath=introduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.jolin.io\" target=\"_blank\" rel=\"noreferrer noopener\">\n",
    "<img src=\"https://www.jolin.io/assets/Jolin/Jolin-Banner-Website-v1.1-darkmode.webp\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call me Stephan\n",
    "\n",
    "Hi there, I am Stephan Sahm, founder of [Jolin.io](www.jolin.io) consulting and organizer of the [Julia User Group Munich](https://www.meetup.com/julia-user-group-munich/).\n",
    "\n",
    "We at [Jolin.io](www.jolin.io) bring Julia into production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Julia\n",
    "\n",
    "- **R** is lovely for statistics and reports, the language and the whole community is build for it and has excellent support\n",
    "- **Python** is your tool if you want to have things done, it has the largest package ecosystem of all languages\n",
    "- **Julia** is made for high performance computing\n",
    "\n",
    "Think of Julia as the new Fortran\n",
    "- excellent runtime performance (like Fortran)\n",
    "- high level language (actually Fortran also tries to be high-level, it just doesn't match today's standards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia 101\n",
    "\n",
    "Julia is really simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [\n",
    "    1 2\n",
    "    3 4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigarray = [\n",
    "    array        array .* 10\n",
    "    1 ./ array   zeros(2, 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function myfunction(x)\n",
    "    if x > 3\n",
    "        \"big\"\n",
    "    else\n",
    "        \"small\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunction.(bigarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia's top ingredients 1/2: `structs`\n",
    "\n",
    "composed data types with speed like c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Cat\n",
    "    name\n",
    "end\n",
    "\n",
    "struct Dog\n",
    "    # :: type annotations\n",
    "    name::String\n",
    "    age::Int\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ðŸ± = Cat(\"kitty\")\n",
    "ðŸ• = Dog(\"dexter\", 2)\n",
    "\n",
    "ðŸ±.name, ðŸ•.name, ðŸ•.age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia's top ingredients 2/2: `functions`\n",
    "\n",
    "overloadable functions with runtime dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(animal) = \"This is $(animal.name)\"\n",
    "\n",
    "describe(ðŸ•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meet(animal1, animal2) = \"$(animal1.name) meets $(animal2.name)\"\n",
    "\n",
    "meet(ðŸ•, ðŸ±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function our_little_story(animal1, animal2)\n",
    "    return [\n",
    "        describe(animal1)\n",
    "        describe(animal2)\n",
    "        meet(animal1, animal2)\n",
    "    ]\n",
    "end\n",
    "\n",
    "our_little_story(ðŸ±, ðŸ•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(dog::Dog) = \"This is $(dog.name) and it is $(dog.age) years old\"\n",
    "\n",
    "meet(cat::Cat, dog::Dog) = \"The awesome cat $(cat.name) meets our $(dog.age) years old dog $(dog.name).\"\n",
    "\n",
    "our_little_story(ðŸ±, ðŸ•)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little challenge for you\n",
    "\n",
    "Define a duck ðŸ¦† and tell a story about your duck meeting kitty ðŸ± or dexter ðŸ•, your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Deep Learning\n",
    "\n",
    "The whole julia language is auto-differentiable.\n",
    "\n",
    "\n",
    "Here a cpu version of the [quickstart example](https://fluxml.ai/Flux.jl/stable/models/quickstart/) from [Flux.jl](https://github.com/FluxML/Flux.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics, ProgressMeter, Plots\n",
    "\n",
    "# Generate some data for the XOR problem: vectors of length 2, as columns of a matrix:\n",
    "noisy = rand(Float32, 2, 1000)                                    # 2Ã—1000 Matrix{Float32}\n",
    "truth = [xor(col[1]>0.5, col[2]>0.5) for col in eachcol(noisy)]   # 1000-element Vector{Bool}\n",
    "\n",
    "scatter(noisy[1,:], noisy[2,:], zcolor=truth, title=\"True classification\", legend=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Dense(2 => 3, tanh),   # activation function inside layer\n",
    "    BatchNorm(3),\n",
    "    Dense(3 => 2),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "# The model encapsulates parameters, randomly initialised. Its initial output is:\n",
    "out1 = model(noisy)\n",
    "scatter(noisy[1,:], noisy[2,:], zcolor=out1[1,:], title=\"Untrained network\", label=\"\", clims=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the model, we use batches of 64 samples, and one-hot encoding:\n",
    "target = Flux.onehotbatch(truth, [true, false]) # 2Ã—1000 OneHotMatrix\n",
    "loader = Flux.DataLoader((noisy, target), batchsize=64, shuffle=true);\n",
    "# 16-element DataLoader with first element: (2Ã—64 Matrix{Float32}, 2Ã—64 OneHotMatrix)\n",
    "\n",
    "losses = []  # will store training progress\n",
    "optim = Flux.setup(Flux.Adam(0.01), model)  # will store optimiser momentum, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop, using the whole data set 1000 times:\n",
    "@showprogress for epoch in 1:1_000\n",
    "    for (x, y) in loader\n",
    "        loss, grads = Flux.withgradient(model) do m\n",
    "            # Evaluate model and loss inside gradient context:\n",
    "            y_hat = m(x)\n",
    "            Flux.crossentropy(y_hat, y)\n",
    "        end\n",
    "        Flux.update!(optim, model, grads[1])\n",
    "        push!(losses, loss)  # logging, outside gradient context\n",
    "    end\n",
    "end\n",
    "\n",
    "optim # parameters, momenta and output have all changed\n",
    "\n",
    "plot(losses; xaxis=(:log10, \"iteration\"), yaxis=\"loss\", label=\"per batch\")\n",
    "n = length(loader)\n",
    "plot!(n:n:length(losses), mean.(Iterators.partition(losses, n)), label=\"epoch mean\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = model(noisy)\n",
    "scatter(noisy[1,:], noisy[2,:], zcolor=out2[1,:], title=\"Trained network\", legend=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(out) = mean((out[1,:] .> 0.5) .== truth)\n",
    "accuracy(out1), accuracy(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further details about the Flux ecosystem can be found at [fluxml.ai](https://fluxml.ai/). \n",
    "To define your own Flux layers in julia, checkout [this tutorial](https://fluxml.ai/Flux.jl/stable/models/basics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you\n",
    "\n",
    "Next is [2. How to use Julia directly at Kaggle](https://www.kaggle.com/stephansahm/titanic-tutorial-julia-version).\n",
    "\n",
    "If you have any questions, you can reach me at stephan.sahm@jolin.io"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "520e995520d0f28b9f1e7cacfd9ba1493aa60b57e5f0cc1543205df7dd9220a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
